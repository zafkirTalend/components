<project xmlns="http://maven.apache.org/POM/4.0.0" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd">
    <modelVersion>4.0.0</modelVersion>

    <parent>
        <groupId>org.talend.components</groupId>
        <artifactId>components-adapter-beam-parent</artifactId>
        <version>0.20.0-SNAPSHOT</version>
        <relativePath>../../../core/components-adapter-beam-parent/pom.xml</relativePath>
    </parent>

    <artifactId>simplefileio-runtime</artifactId>

    <name>Components - Simple File IO Runtime</name>
    <packaging>jar</packaging>

    <properties>
        <hadoop.version>2.7.0</hadoop.version>
        <!-- See below on information for hadoop-aws. -->
        <hadoop.aws.artifactId>hadoop-aws-tlnd</hadoop.aws.artifactId>
        <hadoop.aws.version>2.7.3.1-SNAPSHOT</hadoop.aws.version>
        <parquet.version>1.9.0</parquet.version>
        <spark.version>1.6.0</spark.version>
        <coverage.sonar.reportRoot>${project.basedir}/..</coverage.sonar.reportRoot>
    </properties>

    <dependencies>

        <!-- I'm not sure why this is necessary for the Spark runner tests. -->
        <dependency>
            <groupId>com.fasterxml.jackson.core</groupId>
            <artifactId>jackson-databind</artifactId>
            <version>2.4.4</version>
            <scope>test</scope>
        </dependency>

        <dependency>
            <groupId>org.talend.components</groupId>
            <artifactId>components-adapter-beam</artifactId>
        </dependency>
        <dependency>
            <groupId>org.talend.components</groupId>
            <artifactId>simplefileio-definition</artifactId>
            <version>${project.version}</version>
        </dependency>

        <!--
        For S3: We are currently using a patched version of Hadoop 2.7.3 hadoop-aws jar:

        * In order to not collide with an existing hadoop-aws.jar on the cluster, the package names have been shaded
          and the file system scheme has been changed to register s3t instead of s3a.

        * Specific versions of Amazon SDK, jackson and joda-time have been included into the jar with shaded packages.
         -->
        <dependency>
            <groupId>org.apache.hadoop</groupId>
            <artifactId>${hadoop.aws.artifactId}</artifactId>
            <version>${hadoop.aws.version}</version>
            <exclusions>
                <exclusion>
                    <groupId>org.apache.hadoop</groupId>
                    <artifactId>hadoop-common</artifactId>
                </exclusion>
                <exclusion>
                    <groupId>com.amazonaws</groupId>
                    <artifactId>*</artifactId>
                </exclusion>
                <exclusion>
                    <groupId>com.fasterxml.jackson.core</groupId>
                    <artifactId>*</artifactId>
                </exclusion>
            </exclusions>
        </dependency>

        <!-- includes avro -->
        <dependency>
            <groupId>org.apache.beam</groupId>
            <artifactId>beam-runners-direct-java</artifactId>
        </dependency>
        <dependency>
            <groupId>org.apache.beam</groupId>
            <artifactId>beam-sdks-java-extensions-protobuf</artifactId>
            <version>${beam.version}</version>
        </dependency>
        <dependency>
            <groupId>org.apache.beam</groupId>
            <artifactId>beam-sdks-java-io-hadoop-common</artifactId>
            <version>${beam.version}</version>
        </dependency>
        <dependency>
            <groupId>org.apache.hadoop</groupId>
            <artifactId>hadoop-client</artifactId>
            <version>${hadoop.version}</version>
            <scope>provided</scope>
        </dependency>
        <dependency>
            <groupId>org.apache.avro</groupId>
            <artifactId>avro-mapred</artifactId>
            <version>${avro.version}</version>
            <classifier>hadoop2</classifier>
            <exclusions>
                <!-- exclude old Jetty version of servlet API -->
                <exclusion>
                    <groupId>org.mortbay.jetty</groupId>
                    <artifactId>servlet-api</artifactId>
                </exclusion>
            </exclusions>
        </dependency>

        <!-- To include in dependencies.txt. -->
        <dependency>
            <groupId>org.apache.commons</groupId>
            <artifactId>commons-lang3</artifactId>
            <version>3.4</version>
        </dependency>

        <!-- CSV format-->
        <dependency>
            <groupId>org.apache.commons</groupId>
            <artifactId>commons-csv</artifactId>
            <version>1.4</version>
        </dependency>

        <!-- PARQUET format -->
        <dependency>
            <groupId>org.apache.parquet</groupId>
            <artifactId>parquet-avro</artifactId>
            <version>${parquet.version}</version>
        </dependency>

        <!-- Tests -->
        <dependency>
            <groupId>org.talend.daikon</groupId>
            <artifactId>daikon</artifactId>
            <classifier>tests</classifier>
            <scope>test</scope>
        </dependency>

        <!-- For Spark integration tests. -->
        <dependency>
            <groupId>org.apache.beam</groupId>
            <artifactId>beam-runners-spark</artifactId>
            <version>${beam.version}</version>
            <scope>test</scope>
        </dependency>
        <!-- necessary for Spark unit tests -->
        <dependency>
            <groupId>org.apache.spark</groupId>
            <artifactId>spark-core_2.10</artifactId>
            <version>${spark.version}</version>
            <scope>test</scope>
        </dependency>
        <dependency>
            <groupId>org.apache.spark</groupId>
            <artifactId>spark-streaming_2.10</artifactId>
            <version>${spark.version}</version>
            <scope>test</scope>
        </dependency>
        <dependency>
            <groupId>org.apache.hadoop</groupId>
            <artifactId>hadoop-yarn-client</artifactId>
            <version>${hadoop.version}</version>
            <scope>test</scope>
        </dependency>
        <dependency>
            <groupId>org.apache.spark</groupId>
            <artifactId>spark-yarn_2.10</artifactId>
            <version>${spark.version}</version>
            <scope>test</scope>
        </dependency>

        <!-- For dependency resolution. -->
        <dependency>
            <groupId>org.talend.components</groupId>
            <artifactId>components-api</artifactId>
            <classifier>tests</classifier>
            <scope>test</scope>
        </dependency>
        <dependency>
            <groupId>org.ops4j.pax.url</groupId>
            <artifactId>pax-url-aether</artifactId>
            <version>2.4.7</version>
            <scope>test</scope>
        </dependency>

        <!-- MiniDFSCluster -->
        <dependency>
            <groupId>org.apache.hadoop</groupId>
            <artifactId>hadoop-hdfs</artifactId>
            <version>${hadoop.version}</version>
            <type>test-jar</type>
            <scope>test</scope>
        </dependency>
        <dependency>
            <groupId>org.apache.hadoop</groupId>
            <artifactId>hadoop-common</artifactId>
            <version>${hadoop.version}</version>
            <type>test-jar</type>
            <scope>test</scope>
        </dependency>
    </dependencies>
    <build>
        <plugins>
            <plugin>
                <groupId>org.apache.maven.plugins</groupId>
                <artifactId>maven-failsafe-plugin</artifactId>
                <version>2.20-PAXEXAM-PATCH</version>
                <executions>
                    <execution>
                        <goals>
                            <goal>integration-test</goal>
                            <goal>verify</goal>
                        </goals>
                    </execution>
                </executions>
                <configuration>
                    <argLine>-Xms512m -Xmx1024m ${jacoco.agent.it.argLine}</argLine>
                    <systemPropertyVariables>
                        <s3.accesskey>${s3.accesskey}</s3.accesskey>
                        <s3.secretkey>${s3.secretkey}</s3.secretkey>
                        <s3.region>${s3.region}</s3.region>
                        <s3.bucket>${s3.bucket}</s3.bucket>
                        <s3.ssekmskey>${s3.ssekmskey}</s3.ssekmskey>
                        <s3.csekmskey>${s3.csekmskey}</s3.csekmskey>
                    </systemPropertyVariables>
                </configuration>
            </plugin>
        </plugins>
    </build>
</project>
